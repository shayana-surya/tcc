---
title: "TCC"
author: "Rafael"
date: "07/03/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Colocar aqui todas as bibliotecas que forem necessarias ativar para executar uma funcao.

```{r Biblioteca}
library(readxl)
library(REAT)
library(data.table)
```

Leitura das Bases de dados: 2013 e 2018

```{r Leitura dos Dados}
dados2013 <- read_excel(path = "DadosAlimentadoresCEMIG_XY.xlsx",sheet = 1)
dados2018 <- read_excel(path = "DadosAlimentadoresCEMIG_XY.xlsx",sheet = 2)

```

Pontos desenvolvidos nessa etapa:
  * Cruzamento das duas bases de dados no sentido de preencher informações ausentes, como coordenadas
  * Preparacao de uma base de dados única, juntando todos os alimentares com pelo menos um registro de consumo
  * Criacao de uma coluna nessa base de dados, que retrate a diferença de ConsumoMedido entre os anos
  * Criacao de uma base de dados com as linhas removidas durante a limpeza

Explicar aqui como foi feita a remocao de linhas!!!!!!!!!
* Podemos fazer uma EDA para encontrar outliers e discutir se retiramos ou não

```{r Estruturacao da Base de Dados}
joinDados <- merge(x = dados2013, y = dados2018, by="alimentador", all=TRUE)

diffCemigData <- data.table(alimentador = character(),
                            x = numeric(),
                            y = numeric(),
                            difConsumo = numeric()
)

excluidas <- data.table(alimentador = character(),
                        dados2013.x = numeric(),
                        dados2013.y = numeric(),
                        dados2018.x = numeric(),
                        dados2018.y = numeric(),
                        dados2013.consumo = numeric(),
                        dados2018.consumo = numeric()
)

count <- 0

for (i in 1:nrow(joinDados))
{
  if(
    (!is.na(joinDados$ConsumoMedido.x[i]) || !is.na(joinDados$ConsumoMedido.y[i])) &&
    (!is.na(joinDados$x.x[i]) || !is.na(joinDados$x.y[i])) && 
    (!is.na(joinDados$y.x[i]) || !is.na(joinDados$y.y[i]))
  )
  {
    joinDados$ConsumoMedido.x[i] <- replace(x = joinDados$ConsumoMedido.x[i], list = is.na(joinDados$ConsumoMedido.x[i]), values = 0)
    joinDados$ConsumoMedido.y[i] <- replace(x = joinDados$ConsumoMedido.y[i], list = is.na(joinDados$ConsumoMedido.y[i]), values = 0)
    
    if(!is.na(joinDados$x.x[i]) && !is.na(joinDados$y.x[i]))
    {
      validX = joinDados$x.x[i]
      validY = joinDados$y.x[i]
      
    }
    else
    {
      validX = joinDados$x.y[i]
      validY = joinDados$y.y[i]
      
    }
    
    diffCemigData <- rbind(diffCemigData, data.frame(
      alimentador = joinDados$alimentador[i],
      x = validX,
      y = validY,
      difConsumo = joinDados$ConsumoMedido.y[i] - joinDados$ConsumoMedido.x[i]
      
    ))
  }
  else
  {
    excluidas <- rbind(excluidas, data.frame(
      alimentador = joinDados$alimentador[i],
      dados2013.x = joinDados$x.x[i],
      dados2013.y = joinDados$y.x[i],
      dados2018.x = joinDados$x.y[i],
      dados2018.y = joinDados$y.y[i],
      dados2013.consumo = joinDados$ConsumoMedido.x[i],
      dados2018.consumo = joinDados$ConsumoMedido.y[i]
    ),fill=TRUE)
  }
}

```

Em seguida, estou calculando a matriz de distancia euclidiana entre os alimentadores. Salvando o resultado em um dataframe.
O que podemos avaliar aqui:
  * Como remover essas informações em vermelho que aparecem
  *239.25 tempo decorrido -> representa segundos. Cerca de 4min
Importante: está produzindo NaNs. Acho que devemos repensar como foi feito o tratamento das duas bases. Pode ser que esteja pegando o consumo de um ano e subtraindo de um consumo não registrado no outro ano

```{#r Calculo Distancia Euclidiana}
ti <- proc.time()
matrizDistancia <- dist.mat(diffCemigData,"alimentador","y","x",diffCemigData,"alimentador","y","x")
proc.time() - ti

```

Uma forma alternativa de gerar nossa matriz de distancia
Aqui ao inves de tratar os alimentadores pela sigla, iremos utilizar o indice das linhas que eles ocupam na base diffCemigData
Mas antes precisarei criar uma coluna de indices na diffcemigData, assim eu consigo usar a mesma função dist.mat

```{r Incluindo coluna ID}

diffCemigData$ID <- 1:nrow(diffCemigData)

```

Obtido a matriz de distâncias em um tempo melhor: 179,48seg ou 3min
Podemos ignorar a antiga forma de calcular!

```{r Calculo Distancia Euclidiana por ID}
ti <- proc.time()
matrizDistanciaID <- dist.mat(diffCemigData,"ID","y","x",diffCemigData,"ID","y","x")
proc.time() - ti

```


Ordenando o dataframe em função da coluna "From" e da coluna "Distancia"
Isso facilita muito na hora de encontrar os alimentadores mais proximos, independentemente de utilizarmos a logica dos K mais proximos ou a logica do raio de distancia.

```{r Ordenando o DF}
matrizDistanciaID <- matrizDistanciaID[order( matrizDistanciaID$from,matrizDistanciaID$distance),]
```

Aqui, uma relacao de estruturas, variaveis que serao necessarias durante a varredura
  centroides: lista que guarda os nomes dos alimentadores. Isso ajuda no acesso aos dados.
  clusters: cada linha guarda um cluster, a primeria coluna e o cluster de origem e a ultima e o valor da estatistica de teste calculada
  df_aux: armazena um "recorte" de matriz2013, apenas as linhas de um alimentador origem selecionado (o centroide utilizado por iteracao)
  resultados: dataframe para salvar temporariamente os k vizinhos mais proximos
  somatorio: variavel para calcular o valor da estatistica de teste a cada iteracao
  k: numero de vizinhos proximos a serem inseridos no cluster
  

```{r Auxiliares}
centroides <- diffCemigData$ID
clusters <- data.frame()
clustersSimul <- data.frame()
resultSimul <- vector()
df_aux <- data.frame()
#resultados <- data.frame()
#somatorio <- 0
#k <- 10

```

Aqui, vou calcular todos os dados gerais da população que serão necessários para chegar no valor da estatística de teste. Quais são esses dados:
*Desvio Padrao; Variancia; e Media;
*Somatorio da variavel diferenca de consumo
*Somatorio do quadrado da variavel diferenca de consumo
*Somatorio em i do quadrado da diferenca de consumo menos a media, isso dividido por 2 vezes a variancia
*Parte fixa da estatistica de teste

Tempo: 7 a 8seg

```{r Calculos com base na Populacao}
ti <- proc.time()
N <- length(centroides) #Equivale ao total geral de observacoes
mi <- mean(diffCemigData$difConsumo) #Media geral da diferenca de consumo
sigma2 <- var(diffCemigData$difConsumo) #Variancia geral da diferenca de consumo
sigma <- sd(diffCemigData$difConsumo) #Desvio padrao geral da diferenca de consumo
X <- 0 #Somatorio da variavel diferenca de consumo
Qgeral <- 0 #Somatorio do quadrado da variavel diferenca de consumo
parte2 <- 0 #Somatorio em i do quadrado da diferenca de consumo menos a media, isso dividido por 2 vezes a variancia

for (e in 1:N) {
  X <- X + as.numeric(diffCemigData[e,4])
  Qgeral <- Qgeral + as.numeric((diffCemigData[e,4])^2)
  parte2 <- parte2 + ((diffCemigData[e,4]-mi)^2)/(2*sigma2)
}

fixa <- as.numeric((N*log(sigma) + parte2 - N/2))

proc.time() - ti

```

Testei quanto tempo levaria para gerar todos os clusters possíveis
Com while: 328seg
Com for: 330seg
Tempo decorrido: 330s ou 5min
Logo o que tem maior custo cumputacional está na hora de calcular as coisas

Ao adicionar o calculo do Xz:
Com for: 338seg ou 5,6min

Ao adicionar o calculo do somatorio:
Com for: 410seg ou 6,8min

Ao adicionar os calculos restantes:
Com for: 406seg ou 6,7min

```{#r bloco de testes 1}
dados <- diffCemigData
#result <- data.frame()
resultadosteste <- data.frame()
ti <- proc.time()
#y <- 1
for(y in 1:length(centroides)) {
  df_auxteste <- matrizDistancia[matrizDistancia$from == centroides[y], ]
  #resultadosteste <- data.frame()
  estatistica <- 0
  sigma2z <- 0
  Xz <- 0
  somatorio <- 0
  for(j in 1:10 ){
    resultadosteste[y,j] <- as.character(df_auxteste[j, 2])
    somatorio <- somatorio + as.numeric((dados[dados$alimentador == resultadosteste[y,j],4])^2)
    Xz <- Xz + as.numeric(dados[dados$alimentador == resultadosteste[y,j],4])
  }
  
  #Nz <- as.numeric(length(resultadosteste[y,]))
  #miz <- Xz/Nz
  #lambdaz <- (X - Xz)/(N - Nz)
  
  #sigma2z <- (1/N) * (somatorio - 2*Xz*miz + Nz*(miz^2) + (Qgeral - somatorio) - 2*(X - Xz)*lambdaz + (N - Nz)*(lambdaz^2))
  #estatistica <- fixa - N*log(sqrt(sigma2z))
  
  estatistica <- 1
  resultadosteste[y,j+1] <- estatistica
  #result <- resultadosteste

}
proc.time() - ti
#as.numeric((dados[dados$alimentador == resultadosteste[1,1],4])^2)
#(dados[dados$alimentador == resultadosteste[1,1],4])^2

```
Rodei sem o rbind e obtive resultados em 378seg

```{#r}
resultados <- data.frame()
df_aux <- matrizDistanciaID[matrizDistanciaID$from == centroides[1], ]
resultados[1,1] <- df_aux[2, 2]
resultados[1,1]
a <- as.numeric_version(resultados[1,1])
a
as.numeric(as.numeric_version(resultados[1,1]))
diffCemigData[as.numeric(as.numeric_version(resultados[1,1])),4]
as.numeric(diffCemigData[as.numeric(as.numeric_version(resultados[1,1])),4])
y <- as.numeric(as.numeric_version(resultados[1,1]))
y

```

Fazendo as alterações para a matriz de ID, ficou mais demorado o código
tempo: 470seg

```{#r bloco de testes 2}
k <- 10
ti <- proc.time()
dados <- diffCemigData
resultados <- data.frame()
for (i in 1:nrow(diffCemigData)) {
  estatistica <- 0
  sigma2z <- 0
  #resultados <- data.frame()
  somatorio <- 0 #Somatorio do quadrado da variavel diferenca de consumo dentro do cluster
  Xz <- 0 #Somatorio da variavel diferenca de consumo dentro do cluster
  df_aux <- matrizDistanciaID[matrizDistanciaID$from == centroides[i], ]
    
  for (j in 1:k) {
    
    resultados[i,j] <- df_aux[j, 2]
    linha <- as.numeric(as.numeric_version(resultados[i,j]))
    somatorio <- somatorio + as.numeric((dados[linha,4]))^2
    Xz <- Xz + as.numeric(dados[linha,4])
  }
  
  Nz <- k
  miz <- Xz/Nz
  lambdaz <- (X - Xz)/(N - Nz)
  
  sigma2z <- (1/N) * (somatorio - 2*Xz*miz + Nz*(miz^2) + (Qgeral - somatorio) - 2*(X - Xz)*lambdaz + (N - Nz)*(lambdaz^2))
  estatistica <- fixa - N*log(sqrt(sigma2z))
  
  resultados[i,j+1] <- estatistica
  
}
proc.time() - ti

resultados <- resultados[order(resultados[k+1],decreasing = TRUE),]

```


Abaixo, o algoritmo que gera os clusters
Nele tambem sera calculado o sigma2Z e a estatistica de teste, aproveitando dos valores obtidos no chunck anterior
No final, teremos em cada linha de clusters um cluster com a estatistica de teste na ultima coluna

Mudando a dinamica: vamos criar uma funcao responsavel por gerar os clusters. Assim podemos acionar ela no algoritmo de MonteCarlo
*Matriz de distancia e a mesma, nao vai alterar
*Unica coisa que precisa ser alterada e a base diffcemigdata e tbm a logica de guardar os clusters
*resultsimul vai salvar o melhor resultado para cada iteracao. Depois geramos um histograma disso


```{#r Funcao que gera clusters}

geradorCluster <- function(flag,k,dados){
  #clusters <- data.frame()
  i <- 1
  while (i <= length(centroides)) {
    estatistica <- 0
    sigma2z <- 0
    resultados <- data.frame()
    somatorio <- 0 #Somatorio do quadrado da variavel diferenca de consumo dentro do cluster
    Xz <- 0 #Somatorio da variavel diferenca de consumo dentro do cluster
    df_aux <- matrizDistancia[matrizDistancia$from == centroides[i], ]
    
    for (j in 1:k) {
      resultados[i,j] <- as.character(df_aux[j, 2])
      somatorio <- somatorio + as.numeric((dados[dados$alimentador == resultados[i,j],4])^2)
      Xz <- Xz + as.numeric(dados[dados$alimentador == resultados[i,j],4])
    }
  
    Nz <- as.numeric(length(resultados[i,]))
    miz <- Xz/Nz
    lambdaz <- (X - Xz)/(N - Nz)
  
    sigma2z <- (1/N) * (somatorio - 2*Xz*miz + Nz*(miz^2) + (Qgeral - somatorio) - 2*(X - Xz)*lambdaz + (N - Nz)*(lambdaz^2))
    estatistica <- fixa - N*log(sqrt(sigma2z))
  
    resultados[i,j+1] <- estatistica
    
    clusters <- rbind(clusters,resultados)
    
    i <- i+1
  }
  
  clusters <- na.omit(clusters)
  clusters <- clusters[order(clusters[k+1],decreasing = TRUE),]
  
  
  if(flag==0){
    return(clusters)
  }
  else{
    return(as.numeric(clusters[1,k+1]))
  }
  
}

```

Abaixo uma copia da funcao de cluster. Dessa vez sem o rbind

```{#r clusters copia}

geradorCluster <- function(flag,k,dados){
  
  resultados <- data.frame()
  
  for (i in 1:length(centroides)) {
    estatistica <- 0
    sigma2z <- 0
    
    somatorio <- 0 #Somatorio do quadrado da variavel diferenca de consumo dentro do cluster
    Xz <- 0 #Somatorio da variavel diferenca de consumo dentro do cluster
    df_aux <- matrizDistancia[matrizDistancia$from == centroides[i], ]
    
    for (j in 1:k) {
      resultados[i,j] <- as.character(df_aux[j, 2])
      somatorio <- somatorio + as.numeric((dados[dados$alimentador == resultados[i,j],4])^2)
      Xz <- Xz + as.numeric(dados[dados$alimentador == resultados[i,j],4])
    }
  
    Nz <- as.numeric(length(resultados[i,]))
    miz <- Xz/Nz
    lambdaz <- (X - Xz)/(N - Nz)
  
    sigma2z <- (1/N) * (somatorio - 2*Xz*miz + Nz*(miz^2) + (Qgeral - somatorio) - 2*(X - Xz)*lambdaz + (N - Nz)*(lambdaz^2))
    estatistica <- fixa - N*log(sqrt(sigma2z))
  
    resultados[i,j+1] <- estatistica
    
  }
  
  resultados <- resultados[order(resultados[k+1],decreasing = TRUE),]
  
  
  if(flag==0){
    return(resultados)
  }
  else{
    return(as.numeric(resultados[1,k+1]))
  }
  
}

```




Uma segunda copia da funcao de cluster

```{r clusters copia 2}

geradorCluster <- function(flag,k,dados){
  
  resultados <- data.frame()
  
  for (i in 1:nrow(dados)) {
    estatistica <- 0
    sigma2z <- 0
    
    somatorio <- 0 #Somatorio do quadrado da variavel diferenca de consumo dentro do cluster
    Xz <- 0 #Somatorio da variavel diferenca de consumo dentro do cluster
    df_aux <- matrizDistanciaID[matrizDistanciaID$from == centroides[i], ]
    
    for (j in 1:k) {
      resultados[i,j] <- df_aux[j, 2]
      linha <- as.numeric(as.numeric_version(resultados[i,j]))
      somatorio <- somatorio + as.numeric((dados[linha,4]))^2
      Xz <- Xz + as.numeric(dados[linha,4])
    }
  
    Nz <- k
    miz <- Xz/Nz
    lambdaz <- (X - Xz)/(N - Nz)
  
    sigma2z <- (1/N) * (somatorio - 2*Xz*miz + Nz*(miz^2) + (Qgeral - somatorio) - 2*(X - Xz)*lambdaz + (N - Nz)*(lambdaz^2))
    estatistica <- fixa - N*log(sqrt(sigma2z))
  
    resultados[i,j+1] <- estatistica
    
  }
  
  resultados <- resultados[order(resultados[k+1],decreasing = TRUE),]
  
  
  if(flag==0){
    return(resultados)
  }
  else{
    return(as.numeric(resultados[1,k+1]))
  }
  
}

```


Vou ter dois df: um que guarda minha base de dados que sera utilizada na simulacao, ou seja, aquela que sofrera randomizacao na variavel consumo. Outro para guardar os resultados de cada simulacao.
Qual a principal diferenca: quando calculei apenas o cluster com os dados reais. Levantei todos os possiveis clusters e salvei no df clusters.Agora, de todos os clusters possiveis de serem gerados eu preciso apenas daquele com maior valor da estatistica de teste.
Tempo decorrido: 966.54 segundos - cerca de 16 min
Rodar 100x levaria cerca de 28hrs

Rodando na estrutura nova, obtive os resultado em 375seg
k=10 -> tempo de 442seg: parece estar tudo ok
470seg na nova politica
k=3 -> 493seg: parece estar tudo OK

```{r Gerando Clusters Base Original}
k <- 10
system.time(clusters <- geradorCluster(0,k,diffCemigData))

```


```{r MonteCarlo}

limite <- 100

ti <- proc.time()
for (m in 1:limite) {
  baseRandom <- diffCemigData
  baseRandom[,4] <- sample(diffCemigData$difConsumo) #randomizando a coluna diferenca de consumo
  resultSimul[m] <- geradorCluster(1,baseRandom)
}
proc.time() - ti

```

```{#r}
resultSimul
length(resultSimul)
hist(resultSimul)

```


```{#r testes}
ti <- proc.time()
nomes <- c("A0","A1","A2","A3","A4","A5")
valor <- c(10,20,30,40,50,60)
teste <- data.frame(nomes,valor)
teste[,2] <- sample(teste$valor)
#clusters[1,11]
proc.time() - ti

vas <- 0
if(vas==1){
  vas
}else{
  vas+5
}

teste <- teste[order(teste[2],decreasing = TRUE),]
```

```{#r}
hist(matrizDistancia$distance)
```

